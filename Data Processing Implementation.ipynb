{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Custom Libraries "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created custom functions to deal with the most common data issues.\n",
    "\n",
    "1. The first function is the completeness ratio function, which assesses the completeness of the dataset by calculating the proportion of complete to missing data for each variable.\n",
    "\n",
    "2. The second function, data_val_erroneous checks if all the data types within a column are consistent. For example, it flags if a column with numerical data has observations with text data instead.\n",
    "\n",
    "3. The third function, data_val_duplicates simply returns the number of duplicate rows in the dataset where the entire row is identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Data_Validation import completness_ratio, data_val_erroneous, data_val_duplicates\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feed = pd.read_csv(\"feed-data.csv\")\n",
    "df_output = pd.read_csv(\"output-data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Processing Pipeline\n",
    "- Merging \n",
    "- Identify missing or incorrect data\n",
    "- Return data file that can be used for further analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Assumptions I Made\n",
    "\n",
    "- Run ID serves as the primary key, enabling the linkage between the two datasets by connecting the experimental input data with the output results.\n",
    "\n",
    " - The Date in both datasets refers to the date the experiment was conducted, ensuring alignment of data across both sources.\n",
    "\n",
    "- Missing weight data (either before or after drying) represents a critical issue that could significantly impact the validity of post-experiment analysis. On the other hand, missing additive measurements, while reducing the granularity of information, still allow for valuable insights to be derived from the remaining data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge(df_feed, df_output, left_on='Run ID', right_on='Run', how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_values(df):\n",
    "    \"Removes rows with missing values expect for the Additive columns\"\n",
    "    additive_columns = ['Additive 1 (g)', 'Additive 2 (g)', 'Additive 3 (g)']\n",
    "    clean_df = df.dropna(subset=[col for col in df.columns if col not in additive_columns])\n",
    "    return clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_date_columns(df):\n",
    "    \"\"\"If the dates in both columns differ, the date from the input file (Date_x) is used.\"\"\"\n",
    "    df['Date'] = df.apply(lambda row: row['Date_x'] if row['Date_x'] != row['Date_y'] else row['Date_y'], axis=1)\n",
    "    df = df.drop(columns=['Date_x', 'Date_y'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haith\\AppData\\Local\\Temp\\ipykernel_18656\\3739832262.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Date'] = df.apply(lambda row: row['Date_x'] if row['Date_x'] != row['Date_y'] else row['Date_y'], axis=1)\n"
     ]
    }
   ],
   "source": [
    "pipeline = [handle_missing_values, combine_date_columns]\n",
    "df = reduce(lambda acc, f: f(acc), pipeline, merged_data)\n",
    "df.to_csv(\"Cleaned_Data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Report Highlighting Data Quality Assessment and Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_quality_report(df, output_file='data_quality_report.txt'):\n",
    "    \"\"\"This function creates a textual data quality report and saves it to a text file.\"\"\"\n",
    "    #Data Completness Summary\n",
    "    completeness_df = completness_ratio(df)\n",
    "    completeness_report = \"Data Completeness:\\n\"\n",
    "    completeness_report += \"------------------\\n\"\n",
    "    for idx, row in completeness_df.iterrows():\n",
    "        completeness_report += f\"- {row['Variable']}: {row['Completeness_Ratio']:.2f}% complete\\n\"\n",
    "    \n",
    "    # Data Type Consistency Summary\n",
    "    data_type_consistency_report = data_val_erroneous(df)\n",
    "    data_type_report = \"Data Type Consistency:\\n\"\n",
    "    data_type_report += \"----------------------\\n\"\n",
    "    data_type_report += data_type_consistency_report + \"\\n\"\n",
    "    \n",
    "    # Date Mismatch Summary\n",
    "    df['Date_feed'] = pd.to_datetime(df['Date_x'], format='%d/%m/%Y')\n",
    "    df['Date_output'] = pd.to_datetime(df['Date_y'], format='%d/%m/%Y')\n",
    "    date_mismatch = (df['Date_feed'] != df['Date_output']).sum()\n",
    "    date_mismatch_report = \"Date Mismatch:\\n\"\n",
    "    date_mismatch_report += \"--------------\\n\"\n",
    "    date_mismatch_report += f\"There are {date_mismatch} rows with mismatched dates between the feed data and output data files.\\n\"\n",
    "    \n",
    "    # Duplicates Summary\n",
    "    duplicates_report = data_val_duplicates(df)\n",
    "    duplicates_section = \"Duplicates:\\n\"\n",
    "    duplicates_section += \"-----------\\n\"\n",
    "    duplicates_section += duplicates_report + \"\\n\"\n",
    "    \n",
    "    # Building the report\n",
    "    report = \"Data Quality Report\\n\"\n",
    "    report += \"===================\\n\\n\"\n",
    "    report += completeness_report + \"\\n\"\n",
    "    report += data_type_report + \"\\n\"\n",
    "    report += date_mismatch_report + \"\\n\"\n",
    "    report += duplicates_section\n",
    "    \n",
    "    with open(output_file, 'w') as file:\n",
    "        file.write(report)\n",
    "    \n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Quality Report\n",
      "===================\n",
      "\n",
      "Data Completeness:\n",
      "------------------\n",
      "- Run ID: 100.00% complete\n",
      "- Date_x: 99.66% complete\n",
      "- Process Start Time: 94.22% complete\n",
      "- Feed Type: 100.00% complete\n",
      "- Feed (g): 93.20% complete\n",
      "- Additive 1 (g): 91.84% complete\n",
      "- Additive 2 (g): 91.84% complete\n",
      "- Additive 3 (g): 20.41% complete\n",
      "- Run: 100.00% complete\n",
      "- Date_y: 99.32% complete\n",
      "- Weight before Drying: 92.18% complete\n",
      "- Weight after Drying: 71.09% complete\n",
      "- Output A (g): 72.11% complete\n",
      "- Speed (RPM): 96.94% complete\n",
      "\n",
      "Data Type Consistency:\n",
      "----------------------\n",
      "Inconsistent data types found: Column 'Feed (g)' may have inconsistent data types: Numerical and Unknown\n",
      "\n",
      "Date Mismatch:\n",
      "--------------\n",
      "There are 4 rows with mismatched dates between the feed data and output data files.\n",
      "\n",
      "Duplicates:\n",
      "-----------\n",
      " The dataset contains 0 duplicates\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data_quality_report(merged_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
